{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e0049b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Schema de Dados para o Pipeline PEDE ---\n",
    "\n",
    "# Lista de colunas que contêm valores numéricos formatados com vírgula (padrão BR)\n",
    "COLUNAS_DECIMAIS = [\n",
    "    'INDE 2024', 'INDE 23', 'INDE 22', 'INDE',\n",
    "    'Cg', 'Cf', 'Ct', \n",
    "    'IAA', 'IEG', 'IPS', 'IPP', 'IDA', 'IPV', 'IAN', \n",
    "    'Mat', 'Por', 'Ing', \n",
    "    'Rec Av1', 'Rec Av2', 'Rec Psicologia'\n",
    "]\n",
    "\n",
    "# Dicionário de tipos para carregamento otimizado (evita inferência errada)\n",
    "SCHEMA_DTYPES = {\n",
    "    'RA': str,                 # ID como string para evitar perda de zeros à esquerda se houver\n",
    "    'Fase': str,\n",
    "    'Fase Ideal': str,\n",
    "    'Pedra': str,\n",
    "    'Pedra 2024': str,\n",
    "    'Pedra 23': str,\n",
    "    'Pedra 22': str,\n",
    "    'Pedra 21': str,\n",
    "    'Pedra 20': str,\n",
    "    'Turma': str,\n",
    "    'Nome Anonimizado': str,\n",
    "    'Gênero': str,\n",
    "    'Instituição de ensino': str,\n",
    "    'Escola': str,\n",
    "    'Defasagem': float,        # Usamos float pois pode conter NaNs\n",
    "    'Nº Av': float,\n",
    "    'Ano ingresso': float,\n",
    "    'Idade': float,\n",
    "    'Ativo/ Inativo': str,\n",
    "    'Avaliador1': str, 'Avaliador2': str, 'Avaliador3': str, \n",
    "    'Avaliador4': str, 'Avaliador5': str, 'Avaliador6': str,\n",
    "    'Destaque IEG': str, 'Destaque IDA': str, 'Destaque IPV': str\n",
    "}\n",
    "\n",
    "# Colunas que devem ser parseadas como data\n",
    "COLUNAS_DATA = ['Data de Nasc']\n",
    "\n",
    "def converter_decimal_ptbr(valor):\n",
    "    \"\"\"\n",
    "    Converte strings numéricas no formato PT-BR (1.000,00) para float Python.\n",
    "    Trata valores nulos e erros como NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(valor) or valor == '' or str(valor).strip() == '#N/A':\n",
    "        return np.nan\n",
    "        \n",
    "    if isinstance(valor, (int, float)):\n",
    "        return float(valor)\n",
    "        \n",
    "    try:\n",
    "        # Remove pontos de milhar e troca vírgula decimal por ponto\n",
    "        limpo = str(valor).replace('.', '').replace(',', '.')\n",
    "        return float(limpo)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Criando dicionário de converters para usar no pd.read_csv\n",
    "CONVERTERS_DECIMAIS = {col: converter_decimal_ptbr for col in COLUNAS_DECIMAIS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "29b95732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema de mapeamento dos nomes de colunas (Variações -> Nome Padrão do Dicionário)\n",
    "# Estrutura: \"Nome Padrão\": [\"Variação 1\", \"Variação 2\", ...]\n",
    "\n",
    "DICTIONARY_MAPPING = {\n",
    "    \"columns\": {\n",
    "        \"Ano Ingresso\": [\"Ano ingresso\"],\n",
    "        \"Data Nascimento\": [\"Ano nasc\", \"Data de Nasc\"],\n",
    "        \"Atingiu PV\": [\"Atingiu PV\"],\n",
    "        \"Avaliador 1\": [\"Avaliador1\"],\n",
    "        \"Avaliador 2\": [\"Avaliador2\"],\n",
    "        \"Avaliador 3\": [\"Avaliador3\"],\n",
    "        \"Avaliador 4\": [\"Avaliador4\"],\n",
    "        \"Avaliador 5\": [\"Avaliador5\"],\n",
    "        \"Avaliador 6\": [\"Avaliador6\"],\n",
    "        \"Cf\": [\"Cf\"],\n",
    "        \"Cg\": [\"Cg\"],\n",
    "        \"Ct\": [\"Ct\"],\n",
    "        \"Defasagem\": [\"Defas\", \"Defasagem\"],\n",
    "        \"Destaque IDA\": [\"Destaque IDA\"],\n",
    "        \"Destaque IEG\": [\"Destaque IEG\"],\n",
    "        \"Destaque IPV\": [\"Destaque IPV\"],\n",
    "        \"Escola\": [\"Escola\"],\n",
    "        \"Fase\": [\"Fase\"],\n",
    "        \"Fase Ideal\": [\"Fase ideal\", \"Fase Ideal\"],\n",
    "        \"Gênero\": [\"Gênero\"],\n",
    "        \"IAA\": [\"IAA\"],\n",
    "        \"IAN\": [\"IAN\"],\n",
    "        \"IDA\": [\"IDA\"],\n",
    "        \"Idade\": [\"Idade 22\", \"Idade\"],\n",
    "        \"IEG\": [\"IEG\"],\n",
    "        # Mapeando qualquer INDE principal (ano corrente da planilha) para \"INDE\"\n",
    "        \"INDE\": [\"INDE 22\", \"INDE 23\", \"INDE 2023\", \"INDE 2024\", \"INDE\"],\n",
    "        \"Indicado\": [\"Indicado\"],\n",
    "        \"Inglês\": [\"Inglês\", \"Ing\"],\n",
    "        \"Instituição de Ensino\": [\"Instituição de ensino\"],\n",
    "        \"IPP\": [\"IPP\"],\n",
    "        \"IPS\": [\"IPS\"],\n",
    "        \"IPV\": [\"IPV\"],\n",
    "        \"Matemática\": [\"Matem\", \"Mat\"],\n",
    "        \"Nome\": [\"Nome\", \"Nome Anonimizado\"],\n",
    "        \"Nº Av\": [\"Nº Av\"],\n",
    "        \"Pedra 20\": [\"Pedra 20\"],\n",
    "        \"Pedra 21\": [\"Pedra 21\"],\n",
    "        \"Pedra 22\": [\"Pedra 22\"],\n",
    "        \"Pedra 23\": [\"Pedra 23\", \"Pedra 2023\"],\n",
    "        \"Pedra 24\": [\"Pedra 2024\"],\n",
    "        \"Português\": [\"Portug\", \"Por\"],\n",
    "        \"RA\": [\"RA\"],\n",
    "        \"Rec Av1\": [\"Rec Av1\"],\n",
    "        \"Rec Av2\": [\"Rec Av2\"],\n",
    "        \"Rec Av3\": [\"Rec Av3\"],\n",
    "        \"Rec Av4\": [\"Rec Av4\"],\n",
    "        \"Rec Psicologia\": [\"Rec Psicologia\"],\n",
    "        \"Turma\": [\"Turma\"],\n",
    "        \"Ativo/Inativo\": [\"Ativo/ Inativo\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Função auxiliar para renomear colunas do DF baseado no mapping\n",
    "def padronizar_colunas(df, mapping):\n",
    "    col_map = {}\n",
    "    for padrao, variacoes in mapping['columns'].items():\n",
    "        for var in variacoes:\n",
    "            if var in df.columns:\n",
    "                col_map[var] = padrao\n",
    "    \n",
    "    return df.rename(columns=col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c77a183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tratar colunas duplicadas no carregamento\n",
    "def remover_colunas_duplicadas(df):\n",
    "    \"\"\"\n",
    "    Remove colunas duplicadas de um DataFrame.\n",
    "    Se houver colunas com o mesmo nome (ex: 'Ativo/ Inativo', 'Ativo/ Inativo.1'),\n",
    "    mantém apenas a primeira ocorrência.\n",
    "    \"\"\"\n",
    "    # Identifica colunas duplicadas (pelo nome original ou pandas sufixos)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    print(f\"Colunas após remoção de duplicatas exatas: {df.shape[1]}\")\n",
    "    \n",
    "    # Tratamento específico para sufixos do Pandas (.1, .2) se o usuário carregar sem mangle_dupe_cols=True\n",
    "    # Mas o padrão do pandas é renomear. Vamos limpar esses nomes se forem cópias.\n",
    "    cols_originais = [c.split('.')[0] for c in df.columns]\n",
    "    \n",
    "    # Se quiser forçar a remoção de colunas que o Pandas renomeou (ex: Coluna.1)\n",
    "    # Verificamos se o \"tronco\" do nome já existe antes\n",
    "    cols_unicas = []\n",
    "    seen = set()\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    for i, col in enumerate(df.columns):\n",
    "        nome_base = col.split('.')[0] # Remove sufixo .1, .2 gerado pelo pandas\n",
    "        \n",
    "        # Lógica: Se o nome base já foi visto E o pandas adicionou sufixo numérico\n",
    "        if nome_base in seen and col != nome_base:\n",
    "            # Verifica se o conteúdo é igual ao original\n",
    "            if df[nome_base].equals(df[col]):\n",
    "                cols_to_drop.append(col)\n",
    "                # print(f\"Coluna duplicada removida: {col} (cópia idêntica de {nome_base})\")\n",
    "            else:\n",
    "                # Se conteúdo diferente, mantém mas avisa\n",
    "                # print(f\"Aviso: Coluna {col} tem nome similar a {nome_base} mas conteúdo diferente. Mantida.\")\n",
    "                pass\n",
    "        else:\n",
    "            seen.add(nome_base)\n",
    "            \n",
    "    if cols_to_drop:\n",
    "        print(f\"Removendo {len(cols_to_drop)} colunas duplicadas pelo Pandas: {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "943b9b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-09 22:24:08.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mThis is an info message\u001b[0m\n",
      "\u001b[32m2026-02-09 22:24:08.843\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[33m\u001b[1mThis is a warning\u001b[0m\n",
      "\u001b[32m2026-02-09 22:24:08.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[31m\u001b[1mThis is an error\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    " \n",
    "logger.add(\n",
    "    \"app.log\",   \n",
    "    format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\",\n",
    "    level=\"DEBUG\"  # Nível de log\n",
    ")\n",
    " \n",
    "\n",
    "logger.info(\"This is an info message\")\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7aa5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando 2022 ---\n",
      "Colunas após remoção de duplicatas exatas: 42\n",
      "Shape: (860, 42)\n",
      "\n",
      "--- Carregando 2023 ---\n",
      "Colunas após remoção de duplicatas exatas: 48\n",
      "Removendo 1 colunas duplicadas pelo Pandas: ['Destaque IPV.1']\n",
      "Shape: (1014, 47)\n",
      "\n",
      "--- Carregando 2024 ---\n",
      "Colunas após remoção de duplicatas exatas: 50\n",
      "Removendo 1 colunas duplicadas pelo Pandas: ['Ativo/ Inativo.1']\n",
      "Shape: (1156, 49)\n",
      "\n",
      "Colunas comuns nos 3 anos: 32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "# Caminho do arquivo\n",
    "file = \"C:/Users/Angélica/Desktop/datathon/projeto_datathon/arquivos/BASE DE DADOS PEDE 2024 - DATATHON.xlsx\"\n",
    "\n",
    "# Função auxiliar de carregamento e limpeza inicial\n",
    "def carregar_aba(excel_file, sheet_name):\n",
    "    # Carrega dados\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "    \n",
    "    # Remove espaços em branco dos nomes das colunas\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Remove colunas duplicadas imediatamente\n",
    "    df = remover_colunas_duplicadas(df)\n",
    "    \n",
    "    # Tratamentos padrão de RA\n",
    "    if 'RA' in df.columns:\n",
    "        df['RA'] = df['RA'].astype(str).str.zfill(7)\n",
    "        \n",
    "    return df\n",
    "\n",
    "print(\"--- Carregando 2022 ---\")\n",
    "df_2022 = carregar_aba(file, \"PEDE2022\")\n",
    "print(f\"Shape: {df_2022.shape}\")\n",
    "\n",
    "print(\"\\n--- Carregando 2023 ---\")\n",
    "df_2023 = carregar_aba(file, \"PEDE2023\")\n",
    "print(f\"Shape: {df_2023.shape}\")\n",
    "\n",
    "print(\"\\n--- Carregando 2024 ---\")\n",
    "df_2024 = carregar_aba(file, \"PEDE2024\")\n",
    "print(f\"Shape: {df_2024.shape}\")\n",
    "\n",
    "# Padronização de nomes (usando o mapping definido anteriormente)\n",
    "# IMPORTANTE: Definir DICTIONARY_MAPPING antes de rodar isso (célula anterior)\n",
    "if 'padronizar_colunas' in locals():\n",
    "    print(\"\\n--- Padronizando Colunas ---\")\n",
    "    df_2022 = padronizar_colunas(df_2022, DICTIONARY_MAPPING)\n",
    "    df_2023 = padronizar_colunas(df_2023, DICTIONARY_MAPPING)\n",
    "    df_2024 = padronizar_colunas(df_2024, DICTIONARY_MAPPING)\n",
    "\n",
    "# Verificar intersecção após padronização\n",
    "cols_comuns = set(df_2022.columns) & set(df_2023.columns) & set(df_2024.columns)\n",
    "print(f\"\\nColunas comuns nos 3 anos: {len(cols_comuns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8677163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando padronização de nomes...\n",
      "=== RELATÓRIO DE COMPARAÇÃO DE ESTRUTURA ===\n",
      "Total de colunas únicas encontradas (união): 49\n",
      "Colunas comuns a todos os anos: 40\n",
      "----------------------------------------\n",
      "⚠️ Diferenças entre 2022 e 2023:\n",
      "   - Exclusivas em 2023: 2 colunas (Pedra 23, IPP...)\n",
      "⚠️ Diferenças entre 2023 e 2024:\n",
      "   - Exclusivas em 2023: 2 colunas (Rec Av3, Rec Av4...)\n",
      "   - Exclusivas em 2024: 5 colunas (Avaliador 6, Escola, Pedra 24, Avaliador 5, Ativo/Inativo...)\n",
      "----------------------------------------\n",
      "\n",
      "=== VALIDAÇÃO DE CONTEÚDO (Colunas Comuns) ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# Dicionário para a função de relatório\u001b[39;00m\n\u001b[32m     80\u001b[39m     dict_dfs = {\n\u001b[32m     81\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m2022\u001b[39m\u001b[33m'\u001b[39m: df_2022_std,\n\u001b[32m     82\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m2023\u001b[39m\u001b[33m'\u001b[39m: df_2023_std,\n\u001b[32m     83\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m2024\u001b[39m\u001b[33m'\u001b[39m: df_2024_std\n\u001b[32m     84\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[43mrelatorio_comparativo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_dfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# Atualizando as variáveis globais para as versões padronizadas (opcional)\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# df = pd.concat(dict_dfs.values(), ignore_index=True) # Se quiser concatenar já\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataFrames não carregados. Execute a célula de leitura primeiro.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mrelatorio_comparativo\u001b[39m\u001b[34m(dfs_dict)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Se houver mais de um tipo diferente para a mesma coluna\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(tipos.values())) > \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         divergencias_tipo.append((col, \u001b[43mtypes\u001b[49m))\n\u001b[32m     51\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ Divergência de Tipo na coluna \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtipos\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m divergencias_tipo:\n",
      "\u001b[31mNameError\u001b[39m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Padronização e Validação Comparativa entre Anos ---\n",
    "\n",
    "def relatorio_comparativo(dfs_dict):\n",
    "    \"\"\"\n",
    "    Compara colunas e conteúdo entre múltiplos DataFrames (anos).\n",
    "    dfs_dict: dicionário {'2022': df22, '2023': df23, ...}\n",
    "    \"\"\"\n",
    "    print(\"=== RELATÓRIO DE COMPARAÇÃO DE ESTRUTURA ===\")\n",
    "    \n",
    "    anos = list(dfs_dict.keys())\n",
    "    cols_sets = {ano: set(df.columns) for ano, df in dfs_dict.items()}\n",
    "    \n",
    "    # 1. Padronização (já aplicada antes desta chamada, mas verificando colunas resultantes)\n",
    "    todas_colunas = set().union(*cols_sets.values())\n",
    "    colunas_comuns = set.intersection(*cols_sets.values())\n",
    "    \n",
    "    print(f\"Total de colunas únicas encontradas (união): {len(todas_colunas)}\")\n",
    "    print(f\"Colunas comuns a todos os anos: {len(colunas_comuns)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 2. Diferenças entre anos adjacentes\n",
    "    for i in range(len(anos) - 1):\n",
    "        ano_a = anos[i]\n",
    "        ano_b = anos[i+1]\n",
    "        \n",
    "        diff_a = cols_sets[ano_a] - cols_sets[ano_b]\n",
    "        diff_b = cols_sets[ano_b] - cols_sets[ano_a]\n",
    "        \n",
    "        if not diff_a and not diff_b:\n",
    "            print(f\"✅ {ano_a} e {ano_b} possuem exatamente as mesmas colunas.\")\n",
    "        else:\n",
    "            print(f\"⚠️ Diferenças entre {ano_a} e {ano_b}:\")\n",
    "            if diff_a:\n",
    "                print(f\"   - Exclusivas em {ano_a}: {len(diff_a)} colunas ({', '.join(list(diff_a)[:5])}...)\")\n",
    "            if diff_b:\n",
    "                print(f\"   - Exclusivas em {ano_b}: {len(diff_b)} colunas ({', '.join(list(diff_b)[:5])}...)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 3. Validação de Conteúdo (Tipos) para colunas comuns\n",
    "    print(\"\\n=== VALIDAÇÃO DE CONTEÚDO (Colunas Comuns) ===\")\n",
    "    divergencias_tipo = []\n",
    "    \n",
    "    for col in sorted(list(colunas_comuns)):\n",
    "        tipos = {}\n",
    "        for ano, df in dfs_dict.items():\n",
    "            tipos[ano] = str(df[col].dtype)\n",
    "        \n",
    "        # Se houver mais de um tipo diferente para a mesma coluna\n",
    "        if len(set(tipos.values())) > 1:\n",
    "            divergencias_tipo.append((col, types))\n",
    "            print(f\"⚠️ Divergência de Tipo na coluna '{col}': {tipos}\")\n",
    "    \n",
    "    if not divergencias_tipo:\n",
    "        print(\"✅ Tipos de dados consistentes nas colunas comuns.\")\n",
    "        \n",
    "    print(\"\\n=== VALIDAÇÃO DE NULOS (Colunas Comuns) ===\")\n",
    "    # Exibir % de nulos para verificar se uma colunas \"sumiu\" conceitualmente (ficou vazia)\n",
    "    for col in sorted(list(colunas_comuns)):\n",
    "        msgs = []\n",
    "        alerta = False\n",
    "        for ano in anos:\n",
    "            pct_null = dfs_dict[ano][col].isnull().mean() * 100\n",
    "            if pct_null > 90: # Se mais de 90% for nulo, alerta\n",
    "                alerta = True\n",
    "            msgs.append(f\"{ano}: {pct_null:.1f}%\")\n",
    "        \n",
    "        if alerta:\n",
    "            print(f\"⚠️ Coluna '{col}' quase vazia em algum ano: \" + \" | \".join(msgs))\n",
    "            \n",
    "    print(\"\\nConclusão da Validação Comparativa Finalizada.\")\n",
    "\n",
    "# Aplicando a padronização antes de comparar\n",
    "if 'df_2022' in locals() and 'df_2023' in locals() and 'df_2024' in locals():\n",
    "    print(\"Aplicando padronização de nomes...\")\n",
    "    df_2022_std = padronizar_colunas(df_2022, DICTIONARY_MAPPING)\n",
    "    df_2023_std = padronizar_colunas(df_2023, DICTIONARY_MAPPING)\n",
    "    df_2024_std = padronizar_colunas(df_2024, DICTIONARY_MAPPING)\n",
    "    \n",
    "    # Dicionário para a função de relatório\n",
    "    dict_dfs = {\n",
    "        '2022': df_2022_std,\n",
    "        '2023': df_2023_std,\n",
    "        '2024': df_2024_std\n",
    "    }\n",
    "    \n",
    "    relatorio_comparativo(dict_dfs)\n",
    "    \n",
    "    # Atualizando as variáveis globais para as versões padronizadas (opcional)\n",
    "    # df = pd.concat(dict_dfs.values(), ignore_index=True) # Se quiser concatenar já\n",
    "else:\n",
    "    print(\"DataFrames não carregados. Execute a célula de leitura primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9934b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-09 23:13:58.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mSistemaPrincipal\u001b[0m:\u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m | \u001b[1mAplicação LeituraArquivos inicializada\u001b[0m\n",
      "\u001b[32m2026-02-09 23:13:58.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mSistemaPrincipal\u001b[0m:\u001b[36m__main__\u001b[0m:\u001b[36mler_arquivo\u001b[0m:\u001b[36m47\u001b[0m | \u001b[1mIniciando leitura de itens\u001b[0m\n",
      "\u001b[32m2026-02-09 23:13:59.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mSistemaPrincipal\u001b[0m:\u001b[36m__main__\u001b[0m:\u001b[36mler_arquivo\u001b[0m:\u001b[36m56\u001b[0m | \u001b[1mDados carregados com sucesso. Shape: (860, 42). Colunas: ['RA', 'Fase', 'Turma', 'Nome', 'Ano nasc', 'Idade 22', 'Gênero', 'Ano ingresso', 'Instituição de ensino', 'Pedra 20', 'Pedra 21', 'Pedra 22', 'INDE 22', 'Cg', 'Cf', 'Ct', 'Nº Av', 'Avaliador1', 'Rec Av1', 'Avaliador2', 'Rec Av2', 'Avaliador3', 'Rec Av3', 'Avaliador4', 'Rec Av4', 'IAA', 'IEG', 'IPS', 'Rec Psicologia', 'IDA', 'Matem', 'Portug', 'Inglês', 'Indicado', 'Atingiu PV', 'IPV', 'IAN', 'Fase ideal', 'Defas', 'Destaque IEG', 'Destaque IDA', 'Destaque IPV']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Adiciona o diretório raiz do projeto ao sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.utils import LoggerConfig, ApplicationLogger\n",
    "\n",
    "class LeituraArquivos:\n",
    "    def __init__(self, name: str = \"LeituraArquivos\", caminho: str = \"data/\"):\n",
    "        \"\"\"\n",
    "        Inicializa a aplicação\n",
    "        \n",
    "        Args:\n",
    "            name: Nome da aplicação\n",
    "            caminho: Caminho padrão para os arquivos\n",
    "        \"\"\"\n",
    "        # Configuração do logger\n",
    "        self.config = LoggerConfig(\n",
    "            app_name=name,\n",
    "            log_dir=f\"logs/{name.lower()}\"\n",
    "        )\n",
    "        \n",
    "        self.logger = ApplicationLogger(self.__class__.__name__, self.config)\n",
    "        \n",
    "        self.logger.logger.info(f\"Aplicação {name} inicializada\")\n",
    "        self.caminho = caminho\n",
    "        \n",
    "    def ler_arquivo(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Lê um arquivo CSV ou Excel e retorna um DataFrame\n",
    "        \n",
    "        Args:\n",
    "            caminho: Caminho do arquivo a ser lido\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame com os dados lidos\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.log_method_call(\"ler_arquivo\", caminho=self.caminho)\n",
    "\n",
    "        if not os.path.exists(self.caminho):\n",
    "            self.logger.log_exception(\"ler_arquivo\", e)\n",
    "            self.logger.logger.error(f\"Arquivo não encontrado: {self.caminho}\") \n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {self.caminho}\")\n",
    "        \n",
    "        self.logger.logger.info(f\"Iniciando leitura de itens\")\n",
    "\n",
    "        if self.caminho.endswith('.xlsx'):\n",
    "            df = pd.read_excel(self.caminho)\n",
    "        else:\n",
    "            self.logger.logger.error(f\"Formato de arquivo não suportado: {self.caminho}\")\n",
    "            self.logger.log_exception(\"ler_arquivo\", e)\n",
    "            raise ValueError(\"Formato de arquivo não suportado. Use .xlsx ou .csv\")\n",
    "\n",
    "        self.logger.logger.info(f\"Dados carregados com sucesso. Shape: {df.shape}. Colunas: {df.columns.tolist()}\")\n",
    "        return df\n",
    "\n",
    "leitura = LeituraArquivos(caminho=\"C:\\\\Users\\\\Angélica\\\\Desktop\\\\datathon\\\\projeto_datathon\\\\arquivos\\\\BASE DE DADOS PEDE 2024 - DATATHON.xlsx\")\n",
    "df = leitura.ler_arquivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1c9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cc3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e709cf",
   "metadata": {},
   "source": [
    "# Validação de Dados e Modelagem Preditiva\n",
    "\n",
    "Nesta seção, realizaremos:\n",
    "1. **Validação dos Dados**: Verificação de consistência, valores nulos e distribuições.\n",
    "2. **Engenharia de Features**: Preparação das variáveis para o modelo.\n",
    "3. **Modelo Preditivo**: Criação de um modelo para estimar o risco de defasagem escolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d567b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Configuração de visualização\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "def validar_dados(df, ano):\n",
    "    \"\"\"\n",
    "    Realiza validações básicas no DataFrame e retorna um relatório.\n",
    "    \"\"\"\n",
    "    print(f\"--- Relatório de Validação: {ano} ---\")\n",
    "    \n",
    "    # 1. Verificar Nulos em Colunas Críticas\n",
    "    cols_criticas = ['RA', 'Fase', 'INDE 2024', 'Pedra 2024', 'Defasagem', 'IAA', 'IEG', 'IPS', 'IPP', 'IDA', 'IPV', 'IAN']\n",
    "    # Ajuste para colunas que podem variar de nome dependendo do ano (ex: INDE 2024 vs INDE 2023)\n",
    "    cols_existentes = [c for c in cols_criticas if c in df.columns]\n",
    "    \n",
    "    nulos = df[cols_existentes].isnull().sum()\n",
    "    if nulos.sum() > 0:\n",
    "        print(\"⚠️ Atenção: Valores nulos encontrados:\")\n",
    "        print(nulos[nulos > 0])\n",
    "    else:\n",
    "        print(\"✅ Colunas críticas sem valores nulos.\")\n",
    "\n",
    "    # 2. Verificar Duplicidade de RA\n",
    "    if 'RA' in df.columns:\n",
    "        duplicados = df['RA'].duplicated().sum()\n",
    "        if duplicados > 0:\n",
    "            print(f\"⚠️ Atenção: {duplicados} RAs duplicados encontrados.\")\n",
    "        else:\n",
    "            print(\"✅ ID (RA) únicos validados.\")\n",
    "            \n",
    "    # 3. Validar Consistência da Coluna Defasagem\n",
    "    if 'Defasagem' in df.columns:\n",
    "        # Converter para numérico se necessário, forçando NaN em erros\n",
    "        df['Defasagem'] = pd.to_numeric(df['Defasagem'], errors='coerce')\n",
    "        print(\"Distribuição da Defasagem:\")\n",
    "        print(df['Defasagem'].value_counts().sort_index())\n",
    "    \n",
    "    print(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "# Assumindo que df_2024 já foi carregado nas células anteriores\n",
    "if 'df_2024' in locals():\n",
    "    validar_dados(df_2024, \"2024\")\n",
    "else:\n",
    "    print(\"DataFrame df_2024 não encontrado na memória.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05f4d5c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y, cols_to_use\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdf_2024\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# Modelagem\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     X, y, feature_names = \u001b[43mpreparar_dados_modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_2024\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Split\u001b[39;00m\n\u001b[32m     49\u001b[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mpreparar_dados_modelo\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     22\u001b[39m     data_model[col] = pd.to_numeric(data_model[col], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Tratamento da Idade (pode ter vindo como numérico ou string datada)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Supondo que Idade já esteja calculada ou numérica. Se não, precisaria calcular.\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 1 = Em Risco (Defasagem < 0)\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 0 = Sem Risco (Defasagem >= 0)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m data_model[\u001b[33m'\u001b[39m\u001b[33mTarget_Risco\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mnp\u001b[49m.where(data_model[\u001b[33m'\u001b[39m\u001b[33mDefasagem\u001b[39m\u001b[33m'\u001b[39m] < \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Remover linhas onde todas as features são nulas\u001b[39;00m\n\u001b[32m     35\u001b[39m data_model.dropna(subset=cols_to_use, how=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Preparação para o Modelo Preditivo ---\n",
    "\n",
    "def preparar_dados_modelo(df):\n",
    "    \"\"\"\n",
    "    Prepara o DataFrame para o treinamento do modelo.\n",
    "    \"\"\"\n",
    "    # 1. Seleção de Features\n",
    "    # Vamos usar as métricas socioemocionais e acadêmicas para prever o risco de defasagem\n",
    "    features = ['IAA', 'IEG', 'IPS', 'IPP', 'IDA', 'IPV', 'IAN', 'Idade']\n",
    "    target = 'Defasagem'\n",
    "    \n",
    "    # Validação se colunas existem\n",
    "    cols_to_use = [col for col in features if col in df.columns]\n",
    "    \n",
    "    data_model = df[cols_to_use + [target]].copy()\n",
    "    \n",
    "    # 2. Tratamento de Dados\n",
    "    # Converter colunas numéricas (empties ou strings com vírgula)\n",
    "    for col in cols_to_use:\n",
    "        if data_model[col].dtype == 'object':\n",
    "            data_model[col] = data_model[col].astype(str).str.replace(',', '.').replace('#N/A', np.nan)\n",
    "        data_model[col] = pd.to_numeric(data_model[col], errors='coerce')\n",
    "    \n",
    "    # Tratamento da Idade (pode ter vindo como numérico ou string datada)\n",
    "    # Supondo que Idade já esteja calculada ou numérica. Se não, precisaria calcular.\n",
    "    \n",
    "    # Tratamento do Target\n",
    "    # Definindo 'Risco' como Defasagem < 0 (ou seja, aluno atrasado)\n",
    "    # 0 = Fase Ideal, < 0 = Atrasado. Vamos criar uma classe binária:\n",
    "    # 1 = Em Risco (Defasagem < 0)\n",
    "    # 0 = Sem Risco (Defasagem >= 0)\n",
    "    data_model['Target_Risco'] = np.where(data_model['Defasagem'] < 0, 1, 0)\n",
    "    \n",
    "    # Remover linhas onde todas as features são nulas\n",
    "    data_model.dropna(subset=cols_to_use, how='all', inplace=True)\n",
    "    \n",
    "    # Imputar valores faltantes nas features com a mediana\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X = imputer.fit_transform(data_model[cols_to_use])\n",
    "    y = data_model['Target_Risco']\n",
    "    \n",
    "    return X, y, cols_to_use\n",
    "\n",
    "if 'df_2024' in locals():\n",
    "    # Modelagem\n",
    "    X, y, feature_names = preparar_dados_modelo(df_2024)\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Treino\n",
    "    modelo = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predição\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Avaliação\n",
    "    print(\"--- Resultados do Modelo de Risco de Defasagem ---\")\n",
    "    print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred, target_names=['Sem Risco', 'Em Risco']))\n",
    "    \n",
    "    # Importância das Variáveis\n",
    "    importancia = pd.DataFrame({'Feature': feature_names, 'Importance': modelo.feature_importances_})\n",
    "    importancia = importancia.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importancia, palette='viridis')\n",
    "    plt.title('Importância das Variáveis na Predição do Risco')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Carregue df_2024 para executar o modelo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08aecb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RA',\n",
       " 'Fase',\n",
       " 'INDE 2024',\n",
       " 'Pedra 2024',\n",
       " 'Turma',\n",
       " 'Nome Anonimizado',\n",
       " 'Data de Nasc',\n",
       " 'Idade',\n",
       " 'Gênero',\n",
       " 'Ano ingresso',\n",
       " 'Instituição de ensino',\n",
       " 'Pedra 20',\n",
       " 'Pedra 21',\n",
       " 'Pedra 22',\n",
       " 'Pedra 23',\n",
       " 'INDE 22',\n",
       " 'INDE 23',\n",
       " 'Cg',\n",
       " 'Cf',\n",
       " 'Ct',\n",
       " 'Nº Av',\n",
       " 'Avaliador1',\n",
       " 'Rec Av1',\n",
       " 'Avaliador2',\n",
       " 'Rec Av2',\n",
       " 'Avaliador3',\n",
       " 'Avaliador4',\n",
       " 'Avaliador5',\n",
       " 'Avaliador6',\n",
       " 'IAA',\n",
       " 'IEG',\n",
       " 'IPS',\n",
       " 'IPP',\n",
       " 'Rec Psicologia',\n",
       " 'IDA',\n",
       " 'Mat',\n",
       " 'Por',\n",
       " 'Ing',\n",
       " 'Indicado',\n",
       " 'Atingiu PV',\n",
       " 'IPV',\n",
       " 'IAN',\n",
       " 'Fase Ideal',\n",
       " 'Defasagem',\n",
       " 'Destaque IEG',\n",
       " 'Destaque IDA',\n",
       " 'Destaque IPV',\n",
       " 'Escola',\n",
       " 'Ativo/ Inativo',\n",
       " 'Ativo/ Inativo.1']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375e6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
